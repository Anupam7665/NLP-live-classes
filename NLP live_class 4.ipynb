{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c9eef91-94a8-4022-a415-0aa655e7e636",
   "metadata": {},
   "source": [
    "### BOW and TF_IDF implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56e42b16-0ef9-4a56-a7c4-d4123e2e5660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'and', 'bag', 'by', 'case', 'corpus', 'demonstrate', 'few', 'first', 'followed', 'in', 'is', 'more', 'of', 'one', 'or', 'our', 'second', 'sentence', 'the', 'third', 'this', 'title', 'to', 'upper', 'with', 'words']\n",
      "There are 27 words in vocabulary.\n",
      "A total of 45 in corpus\n"
     ]
    }
   ],
   "source": [
    "# how to find unique words in your corpus\n",
    "#vocab\n",
    "\n",
    "corpus = [\"This is the first sentence in our corpus followed by one or more sentence to demonstrate Bag of words\",\n",
    "         \"This is the second sentence in our corpus with a FEW UPPER WORDS and Few Title Case Words\",\n",
    "         'this is the third sentence in our corpus']\n",
    "\n",
    "vocab = []\n",
    "total_words = 0\n",
    "\n",
    "for sentence in corpus:\n",
    "    sentence = sentence.lower()\n",
    "    token_temp = sentence.split()\n",
    "    total_words = total_words + len(token_temp)\n",
    "    for i in range(len(token_temp)):\n",
    "        if token_temp[i] not in vocab:\n",
    "            vocab.append(token_temp[i])\n",
    "            \n",
    "vocab.sort()\n",
    "print(vocab)\n",
    "print('There are {} words in vocabulary.'.format(len(vocab)))\n",
    "print('A total of {} in corpus'.format(total_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2c6c6f0-e382-41d1-9d36-4a33269ea944",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "890eaec8-800f-463a-b9f6-2a0c9a1d5ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\"I love Natural language Processing\",\n",
    "        \"creating word vectors\",\n",
    "        \"Is my jam\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92886eb-3091-4197-b81c-444e243e0d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73137c4-8699-4155-9fbb-416a95505964",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "x_bow = cv.fit_transform(data).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13595184-cd87-487e-b504-25d892a28fd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 1, 0, 1, 1, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       "       [0, 1, 1, 0, 0, 1, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6535ceed-bde8-46ed-a8e2-1830bdd6a241",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26702666-f00e-4961-92e3-6d0e3697c5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit \n",
    "\n",
    "tfvectorizer = TfidfVectorizer()\n",
    "vectorized_data = tfvectorizer.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5490811-3a3c-43aa-ab11-6551c8b49112",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tfidf = vectorized_data.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d035b92-f630-48b8-8064-ed21920fcdb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.5       , 0.5       ,\n",
       "        0.        , 0.5       , 0.5       , 0.        , 0.        ],\n",
       "       [0.57735027, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.57735027, 0.57735027],\n",
       "       [0.        , 0.57735027, 0.57735027, 0.        , 0.        ,\n",
       "        0.57735027, 0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67de8d10-fe7b-42db-9fb9-91b5fb08dc34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
